{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04248881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "\n",
    "DATASET_DIR = './VWCADataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1095f1f",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35efcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fec60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc3d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cbcfd",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac013a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset\n",
    "df_CVE = pd.read_csv(DATASET_DIR+'cve_data.csv',low_memory=False)\n",
    "df_CWE = pd.read_csv(DATASET_DIR+'cwe_data.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7b7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these to apply modification\n",
    "df_CWE_updated = df_CWE.copy()\n",
    "df_CWE_updated['index'] = range(len(df_CWE_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969f1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWE id to serial no dictionary\n",
    "id_to_index_dict = dict(zip(df_CWE_updated['ID'], df_CWE_updated['index']))\n",
    "index_to_id_dict = dict(zip(df_CWE_updated['index'], df_CWE_updated['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87e7154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_cwe_ids(cell_value):\n",
    "    processed_array = np.zeros(len(id_to_index_dict))\n",
    "    \n",
    "    if pd.isnull(cell_value):\n",
    "        return processed_array\n",
    "    \n",
    "    cwe_numbers = [int(num) for num in cell_value.split(',') if num.isdigit()]\n",
    "    \n",
    "    for num in cwe_numbers:\n",
    "        if num in id_to_index_dict:\n",
    "            processed_array[id_to_index_dict[num]] = 1    \n",
    "    return processed_array\n",
    "\n",
    "df_CVE_updated = df_CVE.copy()\n",
    "df_CVE_updated['Processed_CWE_IDs'] = df_CVE['Related_CWE_IDs'].apply(process_cwe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97b3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CVE_updated['Labeled'] = df_CVE_updated['Processed_CWE_IDs'].apply(lambda x: any(val == 1 for val in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e958c4ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Related_CWE_IDs</th>\n",
       "      <th>Description</th>\n",
       "      <th>BaseScore</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Exploitability_Score</th>\n",
       "      <th>Impact_Score</th>\n",
       "      <th>Processed_CWE_IDs</th>\n",
       "      <th>Labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-1999-0001</td>\n",
       "      <td>20</td>\n",
       "      <td>ip_input.c in BSD-derived TCP/IP implementatio...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-1999-0002</td>\n",
       "      <td>119</td>\n",
       "      <td>Buffer overflow in NFS mountd gives root acces...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-1999-0003</td>\n",
       "      <td>Other</td>\n",
       "      <td>Execute commands as root via buffer overflow i...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVE-1999-0004</td>\n",
       "      <td>Other</td>\n",
       "      <td>MIME buffer overflow in email clients, e.g. So...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVE-1999-0005</td>\n",
       "      <td>Other</td>\n",
       "      <td>Arbitrary command execution via IMAP buffer ov...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Related_CWE_IDs  \\\n",
       "0  CVE-1999-0001              20   \n",
       "1  CVE-1999-0002             119   \n",
       "2  CVE-1999-0003           Other   \n",
       "3  CVE-1999-0004           Other   \n",
       "4  CVE-1999-0005           Other   \n",
       "\n",
       "                                         Description  BaseScore Severity  \\\n",
       "0  ip_input.c in BSD-derived TCP/IP implementatio...        5.0   MEDIUM   \n",
       "1  Buffer overflow in NFS mountd gives root acces...       10.0     HIGH   \n",
       "2  Execute commands as root via buffer overflow i...       10.0     HIGH   \n",
       "3  MIME buffer overflow in email clients, e.g. So...        5.0   MEDIUM   \n",
       "4  Arbitrary command execution via IMAP buffer ov...       10.0     HIGH   \n",
       "\n",
       "   Exploitability_Score  Impact_Score  \\\n",
       "0                  10.0           2.9   \n",
       "1                  10.0          10.0   \n",
       "2                  10.0          10.0   \n",
       "3                  10.0           2.9   \n",
       "4                  10.0          10.0   \n",
       "\n",
       "                                   Processed_CWE_IDs  Labeled  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    False  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    False  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    False  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CVE_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66c84138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Related_CWE_IDs</th>\n",
       "      <th>Description</th>\n",
       "      <th>BaseScore</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Exploitability_Score</th>\n",
       "      <th>Impact_Score</th>\n",
       "      <th>Processed_CWE_IDs</th>\n",
       "      <th>Labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-1999-0001</td>\n",
       "      <td>20</td>\n",
       "      <td>ip_input.c in BSD-derived TCP/IP implementatio...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-1999-0002</td>\n",
       "      <td>119</td>\n",
       "      <td>Buffer overflow in NFS mountd gives root acces...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CVE-1999-0007</td>\n",
       "      <td>327</td>\n",
       "      <td>Information from SSL-encrypted sessions via PK...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CVE-1999-0027</td>\n",
       "      <td>119</td>\n",
       "      <td>root privileges via buffer overflow in eject c...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CVE-1999-0046</td>\n",
       "      <td>120</td>\n",
       "      <td>Buffer overflow of rlogin program using TERM e...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Related_CWE_IDs  \\\n",
       "0   CVE-1999-0001              20   \n",
       "1   CVE-1999-0002             119   \n",
       "6   CVE-1999-0007             327   \n",
       "26  CVE-1999-0027             119   \n",
       "45  CVE-1999-0046             120   \n",
       "\n",
       "                                          Description  BaseScore Severity  \\\n",
       "0   ip_input.c in BSD-derived TCP/IP implementatio...        5.0   MEDIUM   \n",
       "1   Buffer overflow in NFS mountd gives root acces...       10.0     HIGH   \n",
       "6   Information from SSL-encrypted sessions via PK...        5.0   MEDIUM   \n",
       "26  root privileges via buffer overflow in eject c...        7.2     HIGH   \n",
       "45  Buffer overflow of rlogin program using TERM e...       10.0     HIGH   \n",
       "\n",
       "    Exploitability_Score  Impact_Score  \\\n",
       "0                   10.0           2.9   \n",
       "1                   10.0          10.0   \n",
       "6                   10.0           2.9   \n",
       "26                   3.9          10.0   \n",
       "45                  10.0          10.0   \n",
       "\n",
       "                                    Processed_CWE_IDs  Labeled  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "26  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  \n",
       "45  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     True  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CVE_labeled = df_CVE_updated[df_CVE_updated['Labeled']]\n",
    "df_CVE_labeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b56e3",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1824644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Description\n",
    "        self.targets = self.data.Processed_CWE_IDs\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation = True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            #pad_to_max_length=True,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f106f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (242504, 9)\n",
      "TRAIN Dataset: (124186, 9)\n",
      "TEST Dataset: (31047, 9)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "all_df_CVE = df_CVE_updated.copy()\n",
    "all_df_CVE = all_df_CVE.reset_index(drop=True)\n",
    "train_data=df_CVE_labeled.sample(frac=train_size,random_state=200)\n",
    "test_data=df_CVE_labeled.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(all_df_CVE.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9a176b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d28cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d6a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "VALID_BATCH_SIZE = 2048\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84027589",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CVEDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = CVEDataset(test_data, tokenizer, MAX_LEN)\n",
    "all_set = CVEDataset(all_df_CVE, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d6e58764",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "all_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "all_loader = DataLoader(all_set, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2507b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in enumerate(training_loader):\n",
    "#     print(i,j)\n",
    "#     if i>5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227842b",
   "metadata": {},
   "source": [
    "### LLM Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227100d",
   "metadata": {},
   "source": [
    "- https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb#scrollTo=rcUi1Gd5KCzC\n",
    "\n",
    "- https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "\n",
    "- https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb#scrollTo=MZ_wI0YwDVJZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60e068f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Froze upto:  transformer.layer.5.attention.q_lin.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "V2WBERTClass(\n",
       "  (base_model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=963, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class V2WBERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_class=2):\n",
    "        super(V2WBERTClass, self).__init__()\n",
    "        self.base_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        \n",
    "        layername = 'layer.5'\n",
    "        \n",
    "        for name, param in self.base_model.named_parameters():                       \n",
    "            #print(name)            \n",
    "            if layername in name:\n",
    "                print(\"Froze upto: \", name)\n",
    "                break\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, num_class)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = V2WBERTClass(num_class=len(id_to_index_dict))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a0ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "313d38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3dbe3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i,data in enumerate(pbar :=tqdm(training_loader)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "#         if i%10==0:\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        pbar.set_postfix({'Epoch':epoch, 'Loss': loss.item()})\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "394d39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f65be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [03:01<00:00,  1.49s/it, Epoch=0, Loss=0.00185]\n",
      "100%|██████████| 122/122 [03:02<00:00,  1.50s/it, Epoch=1, Loss=0.00197]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=3, Loss=0.00171]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=4, Loss=0.00183]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=5, Loss=0.00141]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=6, Loss=0.00157]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=7, Loss=0.00137]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=8, Loss=0.00134]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=9, Loss=0.00135]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=10, Loss=0.00141]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=11, Loss=0.00137]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=12, Loss=0.00101]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=13, Loss=0.00131]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=14, Loss=0.00133]\n",
      " 27%|██▋       | 33/122 [00:50<02:13,  1.50s/it, Epoch=15, Loss=0.0012] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 122/122 [03:02<00:00,  1.50s/it, Epoch=21, Loss=0.000933]\n",
      "100%|██████████| 122/122 [03:02<00:00,  1.50s/it, Epoch=22, Loss=0.000796]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=23, Loss=0.000715]\n",
      "100%|██████████| 122/122 [03:03<00:00,  1.50s/it, Epoch=24, Loss=0.000867]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a3c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(pbar :=tqdm(testing_loader)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d08f0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:56<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(testing_loader)\n",
    "# outputs, targets = validation(training_loader)\n",
    "# final_outputs = np.array(outputs) >=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f7aec785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_predictions(outs, ths=0.50):\n",
    "    outs = np.array(outs)\n",
    "    greater_than_threshold = outs >= ths\n",
    "    max_values = np.max(outs, axis=1, keepdims=True)\n",
    "    less_than_threshold = np.isclose(outs,max_values, rtol=0.0001)\n",
    "    result = np.logical_or(greater_than_threshold, less_than_threshold)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "final_outputs = th_predictions(outputs,0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "45aba365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5565a298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Score = 0.7789802557412955\n",
      "Hamming Loss = 0.0004607291373902984\n"
     ]
    }
   ],
   "source": [
    "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
    "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
    "\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff271086",
   "metadata": {},
   "source": [
    "### Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "54d921fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model of....\n",
      "Hamming Score = 0.7789802557412955\n",
      "Hamming Loss = 0.0004607291373902984\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model of....\")\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")\n",
    "\n",
    "torch.save(model.state_dict(), RESULTS_DIR+'2VW24DistilBERTClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c72e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(MODEL_NAME, map_location=lambda storage, loc: storage)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b07b42",
   "metadata": {},
   "source": [
    "### CVEs to CWEs mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9720ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 53/119 [03:09<04:07,  3.75s/it]"
     ]
    }
   ],
   "source": [
    "def prediction(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(pbar :=tqdm(testing_loader)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "                        \n",
    "#             break\n",
    "            \n",
    "    f_targets = np.array(fin_targets) >= 0.25\n",
    "    f_outputs = np.array(fin_outputs) >= 0.25\n",
    "    \n",
    "    true_indices = [np.where(row)[0] for row in f_targets]\n",
    "    pred_indices = [np.where(row)[0] for row in f_outputs]\n",
    "    \n",
    "    print(true_indices[0])\n",
    "    print(pred_indices[0])\n",
    "                \n",
    "    return true_indices, pred_indices\n",
    "\n",
    "#true_indices, pred_indices = prediction(testing_loader)\n",
    "true_indices, pred_indices = prediction(all_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save mapping\n",
    "def save_mapping():\n",
    "    t_cwes = []\n",
    "    p_cwes = []\n",
    "\n",
    "    for row in true_indices:\n",
    "        t_cwes.append([index_to_id_dict[c] for c in row])\n",
    "\n",
    "    for row in pred_indices:\n",
    "        p_cwes.append([index_to_id_dict[c] for c in row])\n",
    "\n",
    "    print(t_cwes[0], p_cwes[0])\n",
    "\n",
    "    all_df_CVE['TrueCWEs']=t_cwes\n",
    "    all_df_CVE['PredCWEs']=p_cwes\n",
    "\n",
    "save_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53407ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_CVE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_CVE.to_csv(RESULTS_DIR+'2VW24DistilBERTClass.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e9ab8",
   "metadata": {},
   "source": [
    "### Transformation to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4cf06983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transform(filename,infos):    \n",
    "    f=open(filename, 'a+')\n",
    "    np.savetxt(f, infos)    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "00ce8888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [08:20<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "def TransformDataset(dataloader, filename):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(pbar :=tqdm(dataloader)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output_1 = model.base_model(input_ids=ids, attention_mask=mask)\n",
    "            hidden_state = output_1[0]\n",
    "            pooler = hidden_state[:, 0]\n",
    "            \n",
    "            save_transform(filename, pooler.detach().cpu().numpy())\n",
    "#             print(pooler.shape)\n",
    "#             break\n",
    "            \n",
    "\n",
    "# filename = RESULTS_DIR+'2VW24DistilBERTClassVec.txt'\n",
    "# f=open(filename, 'w')\n",
    "# f.close()\n",
    "# TransformDataset(all_loader, filename)\n",
    "# TransformDataset(training_loader, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e698f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "# plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2613f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(TAKE=20):\n",
    "    rep=np.loadtxt(filename, dtype=float, max_rows=TAKE)\n",
    "    print(rep.shape)\n",
    "    \n",
    "    transformed = TSNE(n_components=2, perplexity=3, metric='euclidean').fit_transform(rep)\n",
    "    color=all_df_CVE['Processed_CWE_IDs'].iloc[:TAKE].to_numpy()\n",
    "    \n",
    "    print(color.shape)\n",
    "    color = np.stack(color)\n",
    "    print(color.shape)\n",
    "\n",
    "    if(len(color[0])>1):\n",
    "        color=np.argmax(color,axis=1)        \n",
    "        \n",
    "#     print(color)\n",
    "\n",
    "    plt.scatter(transformed[:,0],transformed[:,1], c=color, edgecolor='b', s=500, alpha=0.3 )\n",
    "\n",
    "    for i in range(len(transformed)):\n",
    "        plt.annotate(str(i),(transformed[i,0],transformed[i,1]))\n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "# visualize_data(TAKE=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88999f",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b97b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "# #text = \"Replace me by any text you'd like.\"\n",
    "# text = df_CVE['Description'][0]\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "# output.last_hidden_state.shape\n",
    "# output.last_hidden_state[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df7764e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae257658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             truncation = True,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=100,\n",
    "#             pad_to_max_length=True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8257b2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My py311cu117pyg200 Kernel)",
   "language": "python",
   "name": "py311cu117pyg200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
